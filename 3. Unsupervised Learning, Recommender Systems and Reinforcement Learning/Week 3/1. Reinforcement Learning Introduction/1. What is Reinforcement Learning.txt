Reinforcement learning, while lacking real life applications, is the one the main pillers of machine learning.

Lets learn reinforcement learning through an example of an autonomous helicopter. It is equipped with GPS, Accelerometers, Compass, and a Computer. Radio controlled helicopters are controlled to fly with joysticks, and are quite hard to balance in the air. Andrew Ng and his colleagues at Stanford actually made a helicopter fly upside down. You can check out the videos at http://heli.stanford.edu/ How do you get to do that.

The task is, given the position of the helicopter, how do we move the control sticks. In RL, we call the position, orientation, speed and so on of the helicopter the state 's', so we have to define a function that maps the state of the helicopter 's' to an action 'a', meaning how to move the control sticks to keep it balanced and flying in the air without crashing. One way to approach this problem is using supervised learning. This is not a good approach but for the sake of the argument, we take a bunch of observation of states 'x' and have an expert human pilot tell us what's the best action 'y' to take. We will then use a neural network to map the states 's', which we are calling 'x' here, to a n action 'a', which we are calling 'y' here. But it turns out, the right action to take when the helicopter is moving in the air is very ambiguous. Which is why for other tasks for controlling a robot, like this helicopter, and other robots, the supervised learning approach doesn't work well, so we used reinforcement learning.

One important input into RL is the reward function, which tells the robot when it is doing well and when it is doing poorly. So the way of thinking about the reward function is its a bit like the way you train a dog. To train a dog, you let do it's thing, because you can't demonstrate to it the thing you want it to do, and when it does good, you give it a treat or say "good dog", and whenever you do something bad you say "bad dog", and then you think hopefully it learns by itself the behaviors of the good dog. So training with RL is similar to that. This is one of the ways RL is powerful is the you have to tell it what to do rather then how to do it, and specifying the reward function rather then the optimal action it gives you flexibility in how you design the system.

For training the helicopter to do well using RL, you may give it is flying well you give it a +1 reward or positive reward, and if it is flying poorly you give it a -1 reward or negative reward and additionally, if it ever crashes you give it a very large negative reward like -1000. This well give helicopter incentive to fly well and hopefully to never crash.

RL is applied to wide variety of applications like controlling robots, factory optimization (how to rearrange things in the factory to maximize throughput), financial stock trading (how to sequence out your trades overtime so that you can sell the shares you want to sell and get a good price for them) and playing games like checkers to chess to card and many other video games.