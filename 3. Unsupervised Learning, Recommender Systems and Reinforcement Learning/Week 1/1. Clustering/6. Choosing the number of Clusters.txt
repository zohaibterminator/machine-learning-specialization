For a lot of clustering problems, the value of K is truly ambiguous.

One method of finding the "optimal" number of clusters is called Elbow method. You choose a variety of values of K, and then you plot a graph with the values of K as the x-axis and the cost function for those values at the y-axis. The intuition is, at K=1, the cost function is the highest, when you increase the value of K, the cost function will go down. Then at the value of K that the cost function sort of plateaus out, you pick that. The problem with this is, that for a lot of applications, the value of K is ambiguous, and sometimes the cost function will just go down smoothly and doesnt have a clear elbow point. One logical issue with this is, that if you choosing the value of K by looking at which value of K gives a lower cost value, then pick the largest value of K, that gives the lowest cost value.

Often you select clusters for some later purpose. For example, in the t-shirt sizes example, you can run KMeans for finding the fit of t-shirts for 5 sizes (K=5). Then you can decide whether the trade-off between better fit for shirts vs extra cost of making more t-shirts is better for your business. Another example is Image compression. If you want to compress the image, then based on the value of K, you can decide whether the compressed image looks good enough or not.