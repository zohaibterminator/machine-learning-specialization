Today's recommender system can be made to recommend a handful of movies or ads or songs, etc from a list of millions of such items, so how can we do this efficiently?

Many large scale recommender systems are implemented in 2 steps, a retrieval step, and a ranking step. In the retrieval step, we will generate a large list of plausible candidates, and it can include the items that the user will not like, which is why in the ranking step, we will fine tune our results and pick a certain number of best items to recommend to the user.

For example, in the retrieval step we might do something like return the 10 most similar movies for each of the last 10 movies the user has watched. Meaning, take V_m^(i) and compute V_m^(k), and as we discussed, this can be precomputed. Which means that we can instantly pull up the results using a look up table. This can give you a initial set of movies to recommend to a user that just show up at your website. Additionally, you would like to add to it, the 3 most viewed genres of the user, and then you would add top 10 movies in each of those genres to the list, then you might also add top 20 movies in the country to the list. This can give you a list of 100s of movies. Then you remove duplicate movies or some movies that the users has already watched or the items the user has already purchased.

The second step is the ranking step. You will take the list from the retrieval step, and put them into the learned model. Meaning you will take the user and movie feature vectors X_u and X_m respectively, and put them into their respective NNs to get feature vectors V_u and V_m. And then you will display the ranked list of the movies. One optimization that you can do is if you have already computed feature V_m, you can then perform inference on the user NN, perform dot product of the two, and then give the results.

One decision you have to make is how many movies or items you will retrieve from the dataset to feed into the neural network. Retrieving more items will result in better performance, but slower recommendations. To analyze the tradeoff, try to carry out offline experiments and see if the additional items retrieved have any positive impact on the results.