Let's take the following examples:

1. Is the email spam?
2. Is the transaction fraudulent?
3. Is the tumor malignant?

In each of the above cases, y can be one of two values, Yes and No. This is called binary classification, where binary refers to the possibility of two classes or categories. The two classes can either be denoted by true and false, yes and no or, in our case, 0 and 1. The 0 class, or false class, will be denoted as "negative" class, and the 1 class, or the true class will be denoted as "positive" class. This may not always be true though as it can sometimes be oppositely labelled.

Now lets take the example of a training set for classifying if the tumor is malignant. A class one, positive class, yes class or benign, class zero or negative class. I plotted both the tumor size on the horizontal axis as well as the label Y on the vertical axis. Now, one thing you could try on this training set is to apply the album you already know. Linear regression and try to fit a straight line to the data. Linear regression predicts not just the values zero and one. But all numbers between zero and one or even less than zero or greater than one. But here we want to predict categories. One thing you could try is to pick a threshold of say 0.5. So that if the model outputs a value below 0.5, then you predict why equal zero or not malignant. And if the model outputs a number equal to or greater than 0.5, then predict Y equals one or malignant. So if you draw a vertical line starting from the threshold of 0.5, everything to the left ends up with a prediction of y equals zero, and everything on the right ends up with the prediction of y equals one. This vertical line is called decision boundary. Now, for this particular data set it looks like linear regression could do something reasonable. But now let's see what happens if your dataset has one more training example. What if we add a point all the way to the right? The best fit line for linear regression will shift a bit over to the right, due to the added layer. That means, that the position of the decision boundary will also need to change. So, now if you apply the same method you have been applying, you will see that some of the points will be misclassified. This is why we apply a different algorithm called Logistic Regression that is used to solve binary classification problems (meaning it only outputs 0 and 1).