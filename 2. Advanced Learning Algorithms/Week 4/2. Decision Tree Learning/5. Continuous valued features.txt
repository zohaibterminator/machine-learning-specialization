Lets add another feature to the cats dataset, weight (lbs.). Usually, cats are lighter than dogs, except in a few cases. The process of constructing the DT will be the same except that we will have to decide how to split the continuous variable i.e. the weight. If we were to split the data based on the weight feature, than we can split the data based on whether it is less than or greater than some value, lets say 8 or some other value. This will be the job of the algorithm to choose. We should consider many different values of this threshold and decide to split the data based on whichever threshold gives us the highest I.G. One way to choose this threshold is to sort the values w.r.t the weight, and choose a value in middle section as the threshold.

So to summarize, to get the decision tree to work on continuous value features at every node, when considering splits, you would just consider different values to split on, carry out the usual information gain calculation and decide to split on that continuous value feature if it gives the highest possible information gain.