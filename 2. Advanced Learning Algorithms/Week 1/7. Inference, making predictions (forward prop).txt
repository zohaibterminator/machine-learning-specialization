Lets take a look at the example of an application Handwritten digit recognition. It will be a binary classification between handwritten 0 and 1, where we will input the image and classify, is this the digit 0 or 1?

We are going to use an 8x8 image. And so this image of a one is this grid or matrix of 8x8 or 64 pixel intensity values where 255 denotes a bright white pixel and zero would denote a black pixel. And different numbers are different shades of gray in between the shades of black and white.

We are going to use a neural network with 2 hidden layers, where the first hidden layer has 25 units or neurons, the second hidden layer has 15 units or neurons and the final layer or the output layer will have 3 units or neurons.

First the activation 1 or a^[1] will be calculated, which will act as the input for layer 2, which will output a^[2] which is then acts as input to the output layer which calculates the probabilty of the digit being 1 or not. The output can be classified using a threshold (0.5).

Since the computation takes place from left to right, this algorithm is called forward propagation, because you are propagating activations in the forward direction. This algorithm is used to make predictions. This is in contrast to another algorithm called backward propagation, which is used for learning.

This typical NN architecture, where the initial hidden layer has the most neurons and the number of neurons decrease as you go further, is a typical architecture choice of a NN.