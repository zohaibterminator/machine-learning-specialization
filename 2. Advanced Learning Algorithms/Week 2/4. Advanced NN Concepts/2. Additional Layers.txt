We were using the Dense layer type, where each neuron in the layer gets all the input or activations from the previous layer.

One type of layer is the Convolutional Layer. In this type of layer, each neuron only looks at a part of the previous layer's outputs. One advantage of this type of layer is that it requires less computation time. Another advantage can be is that it requires less training data and can be less prone to overfitting. If you have multiple convolutional layers in your network, than the network is called Convolutional Neural Network.

Lets take an example of EKG/ECG signals or Electro-Cardiograms. The data is in the form of signals that correspond to a person's heartbeat. Suppose there are 100 numbers corresponding to the height of the pulses (x_1 - x_100). The problem is given the ECG signals, classify whether the patient has a heart disease or some diagnosable heart conditions. We will first rotate the data by 90 degrees, and then fed it to a Convolutional NN. Suppose a convolutional layer having 9 neutrons. Lets say that the first neutron looks at the input range x_1 to x_20, the 2nd neutron looks at input range x_11 to x_30. the 3rd neutron looks at input range x_21 to x_40 and so on. Lets say the last neutron looks at input range x_81 to x_100. We add another Convolutional layer with 3 neutrons. Lets say that the 1st neutron of the layer only looks at first 5 activations of the previous layer ,a_1 to a_5. The 2nd neutron looks at the activations from a_3 to a_7 and then the last neutron looks at activations a_5 to a_9. Then we add the final output layer having sigmoid activation that looks at all the activations of the previous layer.

There are lots of architectural choices in a CNN like a neutron should look at how many inputs and a layer should have how many neutrons. By effectively choosing these architectural parameters, we can build better and newer NN that are more effective than dense layer in some applications.