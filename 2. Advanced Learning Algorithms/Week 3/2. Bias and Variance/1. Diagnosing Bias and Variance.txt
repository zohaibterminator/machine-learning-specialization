Across different applications, diagnosing bias and variance gives you a good idea what to do next.

Sometimes, your algorithm will underfit the dataset (have high bias) and other times your algorithm will overfit the dataset (have high variance). And sometimes, you algorithm will perform "just right". If you have just one feature, you can easily find out whether your algorithm is overfitting or underfitting, but if you have more than one feature you cant easily find out by plotting. So you will find this out by looking at the model's performance on the training set and cross-validation set.

To find out if your model has underfitted (has high bias), you will calculate the training error. If the training error is high, it is an indicator that your model has high bias. To find out if your model has overfitted, the training error will be low, but the cross-validation error will be high, indicating that the model doesnt generalize well on data it hasnt seen. If both the training error and cross-validation error is low, then your model has no underfitting and overfitting problems. A model can have high variance (overfitting) and high bias (underfitting) simultaneously, although it is more common in NNs.