If you are building an ML model that serves millions of people, you have to make sure the model is reasonably fair, reasonably free from bias and, you are taking an ethical approach to the application.

Some ML systems in the past exhibit unacceptable level of bias. For example, there was once a hiring tool that exhibited discrimination against women. There was also a facial recognition system that matches dark skinned individuals to criminal mugshots more often than whiter individuals. There were also negative use cases of machine learning algorithms. There was a video released by the company Buzzfeed, which was a deepfake of the then US president Barack Obama. But the company that created this video did so with full transparency and full disclosure. But it would be unethical to generate fake video without consent or disclosure. There was also a model used to generate fake content, for commercial and political purposes.

There isnt a concrete checklist on how to be ethical, so here are some general guidelines on how to be ethical and fair. Firstly, before deploying a potentially harmful, get a diverse team  (diverse in terms of gender, culture, ethnicity to many other traits) to brainstorm ideas on what might go wrong, with emphasis on possible harm to vulnerable groups. In addition, carry out literature search on standards/guidlines for your industry or particular application area. For example, you want a system to approve or reject loans. What it means to be reasonably fair and free from bias and those standards are still emerging in different sectors that could inform your work depending on what you are working on. Auditing the system is also important. If you team has brainstormed ideas that the system you developed is potentially biased towards a certain group, genders, ethnicities, etc, you can audit the system so see if it's true after you have trained it, but before you have deployed it to make sure the system is free from the problems identified prior to releasing it. It is also good to develop a mitigation plan. A simple mitigation plan would be to roll back the system to a previous iteration that we knew were reasonably fair. And then even after deployment to continue to monitor harm so that you can trigger a mitigation plan and act quickly in case a problem emerges.